{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled Dot-Product Attention in PyTorch\n",
    "\n",
    "The basic idea is to compute the attention scores between a set of **queries (Q)** and **keys (K)** and use these scores to weight a set of **values (V)**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Dot-Product Attention\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V\n",
    "$$\n",
    "\n",
    "Where:\n",
    "-  *Q*  is the query matrix\n",
    "-  *K*  is the key matrix\n",
    "-  *V*  is the value matrix\n",
    "-  *d_k* is the dimension of the key vectors (used for scaling)\n",
    "\n",
    "The softmax function => to normalize attention scores, and the output is a weighted sum of the values *V*.\n",
    "\n",
    "### Steps to Implement\n",
    "1. **Compute the dot product of queries and keys**: This gives us raw attention scores.\n",
    "2. **Scale the scores**: divide by \\( \\sqrt{d_k} \\).\n",
    "3. **Apply softmax**:  raw scores into probabilities.\n",
    "4. **Compute the weighted sum of the values**: Multiply the attention weights with the values *V*.\n",
    "\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "**batch_size**:\n",
    "   - **Definition**: The number of sequences (or examples) that are processed together in one forward pass through the model.\n",
    "   -to take advantage of vectorization (parallel processing) and to make training more efficient. \n",
    "   -The **batch_size** specifies how many sequences are included in each batch.\n",
    "\n",
    " **seq_len** (Sequence Length):\n",
    "   - **Definition**: The length of each input sequence (i.e., the number of tokens or words in each sequence).\n",
    "\n",
    " **d_k** (Dimension of the Key and Query vectors):\n",
    "   - **Definition**: The dimensionality of the **key** and **query** vectors in the attention mechanism.\n",
    "\n",
    " **d_v** (Dimension of the Value vector):\n",
    "   - **Definition**: Dimension of the **value** vectors .If **d_v = 128**, each value vector would have 128 dimensions.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "##### Input:\n",
    "- **Q**: $(\\text{batch\\_size}, \\text{seq\\_len}, d_k)$  \n",
    "- **K**: $(\\text{batch\\_size}, \\text{seq\\_len}, d_k)$  \n",
    "- **V**: $(\\text{batch\\_size}, \\text{seq\\_len}, d_v)$  \n",
    "- **Mask** (optional): $(\\text{batch\\_size}, \\text{seq\\_len}, \\text{seq\\_len})$\n",
    "##### Output:\n",
    "- **Attention Output**: $(\\text{batch\\_size}, \\text{seq\\_len}, d_v)$  \n",
    "- **Attention Weights**: $(\\text{batch\\_size}, \\text{seq\\_len}, \\text{seq\\_len})$\n",
    "\n",
    "\n",
    "\n",
    "### Performance\n",
    "##### Time Complexity:\n",
    "$$\n",
    "O(\\text{batch\\_size} \\times \\text{seq\\_len}^2 \\times (d_k + d_v))\n",
    "$$\n",
    "##### Space Complexity:\n",
    "$$\n",
    "O(\\text{batch\\_size} \\times \\text{seq\\_len}^2 + \\text{batch\\_size} \\times \\text{seq\\_len} \\times d_v)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        # The dimension of the key vectors for scaling\n",
    "        self.d_k = d_k \n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Step 1: Calculate dot product of Q and K\n",
    "        # Step 2: Scale the scores by sqrt(d_k)\n",
    "        # Step 3: Apply mask (optional) to prevent attending to certain positions     \n",
    "        # Step 4: Apply softmax to get attention weights\n",
    "        # Step 5: Compute the weighted sum of values (V)\n",
    "        return \"Compute the weighted sum of values\", \"attention_weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7883, 0.9453, 0.2390, 0.1901, 0.9819, 0.0550, 0.4194, 0.5251],\n",
      "         [0.5439, 0.6290, 0.0464, 0.3899, 0.7046, 0.4846, 0.9321, 0.3274],\n",
      "         [0.7153, 0.2226, 0.5617, 0.3809, 0.7121, 0.5881, 0.5029, 0.8936],\n",
      "         [0.5056, 0.2150, 0.2597, 0.1637, 0.6216, 0.4101, 0.7122, 0.0269],\n",
      "         [0.8801, 0.7427, 0.7813, 0.8621, 0.0157, 0.6323, 0.7689, 0.7215]],\n",
      "\n",
      "        [[0.9600, 0.5527, 0.8281, 0.0318, 0.5924, 0.4078, 0.0745, 0.1843],\n",
      "         [0.2264, 0.9531, 0.4066, 0.8108, 0.9573, 0.3994, 0.1344, 0.1221],\n",
      "         [0.8385, 0.7231, 0.6895, 0.0058, 0.3018, 0.0113, 0.7199, 0.3665],\n",
      "         [0.7187, 0.4544, 0.8070, 0.8227, 0.3313, 0.6501, 0.3812, 0.9185],\n",
      "         [0.7793, 0.1678, 0.6792, 0.6064, 0.7477, 0.3379, 0.4711, 0.1097]]])\n",
      "tensor([[[6.6788e-01, 6.0974e-01, 9.0541e-01, 5.4524e-01, 7.9361e-01,\n",
      "          5.9153e-01, 7.7298e-01, 9.0083e-01],\n",
      "         [1.1210e-01, 5.7324e-01, 8.6648e-02, 7.2429e-01, 8.1731e-01,\n",
      "          3.0482e-01, 5.7503e-01, 4.0397e-01],\n",
      "         [9.2063e-02, 2.2902e-01, 6.5938e-01, 8.7990e-01, 9.7869e-01,\n",
      "          2.5889e-01, 2.2309e-01, 5.2532e-01],\n",
      "         [6.2987e-02, 7.5996e-01, 2.3893e-01, 7.3980e-01, 8.8367e-01,\n",
      "          8.9201e-03, 5.1701e-04, 9.2080e-02],\n",
      "         [4.2454e-01, 7.6732e-02, 2.3163e-02, 9.7594e-02, 8.4421e-01,\n",
      "          7.3950e-01, 4.0163e-01, 9.8815e-01]],\n",
      "\n",
      "        [[9.3286e-01, 5.5634e-01, 6.0920e-01, 4.4859e-02, 6.4251e-02,\n",
      "          6.4134e-01, 5.7561e-01, 8.3320e-01],\n",
      "         [4.1031e-01, 3.2019e-02, 1.2214e-01, 4.2818e-01, 6.9879e-01,\n",
      "          3.8972e-01, 8.2474e-01, 3.2956e-01],\n",
      "         [8.4775e-02, 1.4142e-01, 8.2159e-01, 4.5636e-01, 8.2790e-01,\n",
      "          4.5234e-01, 3.2022e-01, 9.6479e-01],\n",
      "         [2.8467e-02, 7.1958e-01, 3.2161e-01, 3.1715e-01, 9.5978e-01,\n",
      "          7.8447e-01, 9.8742e-01, 2.8808e-01],\n",
      "         [5.1489e-01, 9.6529e-01, 2.9022e-01, 7.5301e-01, 4.2011e-01,\n",
      "          5.3516e-01, 2.1083e-02, 3.7022e-01]]])\n",
      "tensor([[[0.6081, 0.2622, 0.3702, 0.5891, 0.4884, 0.5561, 0.1920, 0.4121],\n",
      "         [0.7709, 0.3052, 0.4970, 0.2502, 0.6143, 0.5534, 0.6726, 0.4124],\n",
      "         [0.9165, 0.1706, 0.2978, 0.1589, 0.1525, 0.3927, 0.4972, 0.4940],\n",
      "         [0.0745, 0.1362, 0.3110, 0.6253, 0.9640, 0.4426, 0.8184, 0.2543],\n",
      "         [0.8424, 0.8026, 0.9248, 0.5838, 0.9855, 0.8136, 0.4608, 0.3673]],\n",
      "\n",
      "        [[0.9913, 0.8506, 0.3474, 0.5551, 0.1241, 0.9312, 0.7528, 0.9474],\n",
      "         [0.1525, 0.2179, 0.0922, 0.8422, 0.5790, 0.1579, 0.4554, 0.9612],\n",
      "         [0.2367, 0.9866, 0.0481, 0.4755, 0.8090, 0.9889, 0.3063, 0.2507],\n",
      "         [0.1045, 0.0043, 0.6554, 0.6688, 0.3254, 0.8436, 0.6418, 0.6672],\n",
      "         [0.5155, 0.3466, 0.0049, 0.5083, 0.9719, 0.5057, 0.0711, 0.2695]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 5\n",
    "d_k = 8  \n",
    "d_v = 8  \n",
    "\n",
    "# Generating Random Q, K, V matrices , this will be used to generate attention\n",
    "Q = torch.rand(batch_size, seq_len, d_k)  \n",
    "K = torch.rand(batch_size, seq_len, d_k) \n",
    "V = torch.rand(batch_size, seq_len, d_v) \n",
    "\n",
    "print(Q)\n",
    "print(K)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optionally Masking\n",
    "No masking in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.ones(batch_size, seq_len, seq_len)  \n",
    "print(mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledDotProductAttention()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attention = ScaledDotProductAttention(d_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the attention output and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Output Shape: Compute the weighted sum of values\n",
      "Attention Weights Shape: attention_weights\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output, attention_weights = attention(Q, K, V, mask)\n",
    "\n",
    "# print(\"Attention Output Shape:\", output.shape)\n",
    "print(\"Attention Output Shape:\", output)\n",
    "# print(\"Attention Weights Shape:\", attention_weights.shape)\n",
    "print(\"Attention Weights Shape:\", attention_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
